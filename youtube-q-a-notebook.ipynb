{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Develop a versatile Q&A chatbot, employing LlamaIndex, ASTRA DB (Apache Cassandra), and Gradient's open-source models like LLama2, all designed for seamless interaction with YouTube videos\n",
        "\n"
      ],
      "metadata": {
        "id": "QABLMG8RXbLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhattbhavesh91//youtube-q-a-gradient-astradb/blob/main/youtube-q-a-notebook.ipynb\" target=\"_blank\"><img height=\"40\" alt=\"Run your own notebook in Colab\" src = \"https://colab.research.google.com/assets/colab-badge.svg\"></a>"
      ],
      "metadata": {
        "id": "lIL3e_wNYAYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "mHQ2RrthgyxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q cassandra-driver\n",
        "!pip install -q cassio>=0.1.1\n",
        "!pip install -q gradientai --upgrade\n",
        "!pip install -q llama-index\n",
        "!pip install -q tiktoken==0.4.0\n",
        "!pip install -Uq openai-whisper\n",
        "!pip install -Uq yt-dlp"
      ],
      "metadata": {
        "id": "JVjGvpnwGeSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1937411-2524-48f5-d93f-b28c4147dd7e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.3/166.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.9/834.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.8/217.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.1/153.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "sbuV__oPg0rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import whisper\n",
        "import yt_dlp\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from cassandra.cluster import Cluster\n",
        "from llama_index import ServiceContext\n",
        "from llama_index import set_global_service_context\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader, StorageContext\n",
        "from llama_index.embeddings import GradientEmbedding\n",
        "from llama_index.llms import GradientBaseModelLLM\n",
        "from llama_index.vector_stores import CassandraVectorStore"
      ],
      "metadata": {
        "id": "98-GCZFkNcBs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Audio from YouTube video function"
      ],
      "metadata": {
        "id": "Sm3XHxfUg4Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_audio(link):\n",
        "    with yt_dlp.YoutubeDL({'extract_audio': True,\n",
        "                           'format': 'bestaudio',\n",
        "                           'outtmpl': '%(title)s.mp3'}) as video:\n",
        "        info_dict = video.extract_info(link, download = True)\n",
        "        video_title = info_dict['title']\n",
        "        video.download(link)\n",
        "    return video_title"
      ],
      "metadata": {
        "id": "h-UMWP5hNcE2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example to extract audio -"
      ],
      "metadata": {
        "id": "-u_qn9TEc21A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_video_url = \"https://www.youtube.com/watch?v=Tt0arZN6EBM\""
      ],
      "metadata": {
        "id": "ZlWgwDNLc53m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_audio(youtube_video_url)"
      ],
      "metadata": {
        "id": "YqPAhY8GdIWO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "10486381-199d-4d86-8f74-e8274a30d316"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=Tt0arZN6EBM\n",
            "[youtube] Tt0arZN6EBM: Downloading webpage\n",
            "[youtube] Tt0arZN6EBM: Downloading ios player API JSON\n",
            "[youtube] Tt0arZN6EBM: Downloading android player API JSON\n",
            "[youtube] Tt0arZN6EBM: Downloading m3u8 information\n",
            "[info] Tt0arZN6EBM: Downloading 1 format(s): 251\n",
            "[download] Destination: Why Change Is So Scary -- and How to Unlock Its Potential ｜ Maya Shankar ｜ TED.mp3\n",
            "[download] 100% of   11.35MiB in 00:00:00 at 15.23MiB/s  \n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=Tt0arZN6EBM\n",
            "[youtube] Tt0arZN6EBM: Downloading webpage\n",
            "[youtube] Tt0arZN6EBM: Downloading ios player API JSON\n",
            "[youtube] Tt0arZN6EBM: Downloading android player API JSON\n",
            "[youtube] Tt0arZN6EBM: Downloading m3u8 information\n",
            "[info] Tt0arZN6EBM: Downloading 1 format(s): 251\n",
            "[download] Why Change Is So Scary -- and How to Unlock Its Potential ｜ Maya Shankar ｜ TED.mp3 has already been downloaded\n",
            "[download] 100% of   11.35MiB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why Change Is So Scary -- and How to Unlock Its Potential | Maya Shankar | TED'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transcribe Audio from mp3 file"
      ],
      "metadata": {
        "id": "KL7p7k_ug7KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"text_files\")"
      ],
      "metadata": {
        "id": "SAXE9dOVdzGj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(model, audio):\n",
        "    result = model.transcribe(audio)\n",
        "    with open(\"text_files/transcription.txt\", 'w') as f:\n",
        "        f.write(result[\"text\"])\n",
        "    return 1"
      ],
      "metadata": {
        "id": "RveJfoBrOW0R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/whisper.git -q"
      ],
      "metadata": {
        "id": "0r4ge9LKZsGi",
        "outputId": "3f544907-ea18-4a79-cdbe-662ca50eaa99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "id": "eQ6tTFzwbiCb",
        "outputId": "9e0ea315-07a7-4179-ec04-9ee2c1d2c199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:05<00:00, 95.2MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcribe(model, \"Why Change Is So Scary -- and How to Unlock Its Potential ｜ Maya Shankar ｜ TED.mp3\")"
      ],
      "metadata": {
        "id": "OSyfeEaddTsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f6d9d5-4e58-4e33-ba13-0bcbcf5d12c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup the DataStax Vector DB Connection"
      ],
      "metadata": {
        "id": "v0l4X2WUhJKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cloud_config= {\n",
        "  'secure_connect_bundle': 'secure-connect-ullas-astra-test.zip'\n",
        "}\n",
        "\n",
        "with open(\"ullas_astra_test-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")"
      ],
      "metadata": {
        "id": "SNrNKrJWQoZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3402e3-671b-4ee3-fbf3-72c335d5ab2c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 1b5e0326-f7bd-40fc-beaa-66850c904d73-us-east1.db.astra.datastax.com:29042:611ae092-da92-4dd6-a840-d493f50e4521. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 1b5e0326-f7bd-40fc-beaa-66850c904d73-us-east1.db.astra.datastax.com:29042:611ae092-da92-4dd6-a840-d493f50e4521. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(132771642303312) 1b5e0326-f7bd-40fc-beaa-66850c904d73-us-east1.db.astra.datastax.com:29042:611ae092-da92-4dd6-a840-d493f50e4521> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 1b5e0326-f7bd-40fc-beaa-66850c904d73-us-east1.db.astra.datastax.com:29042:611ae092-da92-4dd6-a840-d493f50e4521. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.11-b86be92b8b5f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Variables"
      ],
      "metadata": {
        "id": "d9_L09rfg2JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GRADIENT_ACCESS_TOKEN'] = 'OnXh8FJJVSSKJgoYSRFJ65QNNJ6x'\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = 'c71d878e-031c07c5c7725b0a_workspace'"
      ],
      "metadata": {
        "id": "PGDEp_2hVHLw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Gradient's Model Adapter for LLAMA-2"
      ],
      "metadata": {
        "id": "TobDHyoJhQD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GradientBaseModelLLM(\n",
        "    base_model_slug = \"llama2-7b-chat\",\n",
        "    max_tokens = 400,\n",
        ")"
      ],
      "metadata": {
        "id": "F9V5V0QwQwwP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure Gradient embeddings"
      ],
      "metadata": {
        "id": "esVcCCmKhWb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = GradientEmbedding(\n",
        "    gradient_access_token = os.environ[\"GRADIENT_ACCESS_TOKEN\"],\n",
        "    gradient_workspace_id = os.environ[\"GRADIENT_WORKSPACE_ID\"],\n",
        "    gradient_model_slug = \"bge-large\",\n",
        ")"
      ],
      "metadata": {
        "id": "U4eC263hQw0d"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup LLAMA Index Service Context"
      ],
      "metadata": {
        "id": "ByfIs25Xhbmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(\n",
        "    llm = llm,\n",
        "    embed_model = embed_model,\n",
        "    chunk_size = 256,\n",
        ")\n",
        "\n",
        "set_global_service_context(service_context)"
      ],
      "metadata": {
        "id": "PQaW3r8tQ1R3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6168d783-626d-483e-8767-736e4fbd585d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Documents"
      ],
      "metadata": {
        "id": "JUCagSnMeA4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"/content/text_files\").load_data()\n",
        "print(f\"Loaded {len(documents)} document(s).\")"
      ],
      "metadata": {
        "id": "SqavzeYDd-UN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55b5852f-f919-4386-dfa3-eecc1cbb26b4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1 document(s).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Query Index"
      ],
      "metadata": {
        "id": "KseDwiXHeKwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        service_context = service_context)\n",
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "zaMdX4vnd-Ww"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_out = query_engine.query(\"What is used to convert speech to text in the text file?\")\n",
        "print(response_out.response)"
      ],
      "metadata": {
        "id": "gKNQxZG9d-ZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0030138-a3d7-43c0-8f94-f34d4fa61697"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The query is asking about the tool or method used to convert speech to text in the text file provided in the context information. Based on the information provided, the answer is \"their breath.\" The speaker mentions that they use their breath to convert speech to text in the text file, suggesting that their breath is the tool or method used for this purpose.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_out = query_engine.query(\"Does this require an API key?\")\n",
        "print(response_out.response)"
      ],
      "metadata": {
        "id": "Ug_rPXMsd-bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe91ac0-eefa-4605-ef6e-cd4dc3632c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes.\n",
            "\n",
            "Explanation: In the video, the speaker mentions that in order to use the Google Cloud Speech to Text API, you will require the credentials of the API. The speaker then goes on to explain how to create a JSON file containing the credentials and how to save it to an environment variable called \"Google underscore application underscore credentials\". This indicates that an API key is required to use the Google Cloud Speech to Text API.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_out = query_engine.query(\"What is a big or small change that you made in your life? How did you overcome the fear of change?\")\n",
        "print(response_out.response)"
      ],
      "metadata": {
        "id": "o0NV_E-2d-eT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28b01445-8fed-4670-c8d2-d98f43d8af81"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A big change I made in my life was quitting my job to pursue my passion for cognitive science. I had been working in the same job for several years, and while it was stable and secure, I found myself feeling unfulfilled and restless. I knew that I needed to make a change, but the fear of the unknown was holding me back.\n",
            "\n",
            "To overcome this fear, I took small steps towards my goal. I started by taking courses in cognitive science and attending seminars related to the field. I also began networking with professionals in the field, which helped me build a support system and gain a better understanding of what was possible.\n",
            "\n",
            "As I gained more confidence in my decision, I began to take bigger steps towards my goal. I quit my job and started my own business, which allowed me to pursue my passion full-time. It was a scary and uncertain time, but I knew that I had to take the leap of faith in order to truly fulfill my potential.\n",
            "\n",
            "Looking back, I realize that the fear of change was holding me back from my true potential. By taking small steps towards my goal and building a support system, I was able to overcome my fear and make a big change in my life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vYX3nnD4a5UK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}